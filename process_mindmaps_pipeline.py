#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€çš„æ€ç»´å¯¼å›¾å¤„ç† Pipeline
å¤„ç† mindmap_raw/ ç›®å½•ä¸‹çš„æ‰€æœ‰ PDF æ–‡ä»¶ï¼Œè½¬æ¢ä¸ºç»Ÿä¸€çš„ mindmap æ ¼å¼
å¹¶è¾“å‡ºåˆ° public/mindmaps/ ç›®å½•
"""

import json
import os
import re
import sys
from pathlib import Path

# æ·»åŠ  scripts ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥å‡çº§è„šæœ¬
sys.path.insert(0, str(Path(__file__).parent / 'scripts'))

try:
    from upgrade_mindmap_data import upgrade_node, slugify
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥å‡çº§è„šæœ¬ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    def slugify(text):
        if not text:
            return ''
        text = re.sub(r'[^\w\s-]', '', text)
        text = re.sub(r'[-\s]+', '-', text)
        return text.lower().strip('-')

# PDF æ–‡ä»¶ååˆ°ç« èŠ‚ç¼–å·çš„æ˜ å°„ï¼ˆæ”¯æŒå¸¦ç©ºæ ¼çš„æ–‡ä»¶åï¼‰
PDF_TO_CHAPTER = {
    'cell.pdf': '1',
    ' cell.pdf': '1',  # å¸¦å‰å¯¼ç©ºæ ¼
    'biomolecule.pdf': '2',
    'enzyme.pdf': '3',
    'membrane structure and transport.pdf': '4',
    'mitosis.pdf': '5',
    'Nucleic acids and protein synthesis.pdf': '6',
    'Transport in Plant.pdf': '7',
    'Transport in mammal.pdf': '8',
    'Gas exchange system.pdf': '9',
    ' Gas exchange system.pdf': '9',  # å¸¦å‰å¯¼ç©ºæ ¼
    'infectious disease.pdf': '10',
    'Immunity.pdf': '11',
}

# ç« èŠ‚ç¼–å·åˆ°è¾“å‡ºæ–‡ä»¶åçš„æ˜ å°„
CHAPTER_TO_FILENAME = {
    '1': '1_Cell_structure.json',
    '2': '2_Biological_molecules.json',
    '3': '3_Enzymes.json',
    '4': '4_Cell_membranes_and_transport.json',
    '5': '5_The_mitotic_cell_cycle.json',
    '6': '6_Nucleic_acids_and_protein_synthesis.json',
    '7': '7_Transport_of_Plant.json',
    '8': '8_Transport_in_mammals.json',
    '9': '9_Gas_exchange.json',
    '10': '10_Infectious_diseases.json',
    '11': '11_Immunity.json',
}

try:
    import pdfplumber
except ImportError:
    print("é”™è¯¯: éœ€è¦å®‰è£… pdfplumber åº“")
    print("è¯·è¿è¡Œ: pip install pdfplumber")
    sys.exit(1)


def extract_text_from_pdf(pdf_path):
    """ä» PDF ä¸­æå–æ–‡æœ¬ï¼Œä¿ç•™ç¼©è¿›ä¿¡æ¯"""
    lines_with_position = []
    
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            chars = page.chars
            
            if not chars:
                text = page.extract_text()
                if text:
                    page_lines = text.split('\n')
                    for line in page_lines:
                        lines_with_position.append((0, line))
                continue
            
            y_groups = {}
            for char in chars:
                y_key = round(char['y0'], 1)
                if y_key not in y_groups:
                    y_groups[y_key] = []
                y_groups[y_key].append(char)
            
            for y_key in sorted(y_groups.keys(), reverse=True):
                chars_in_line = sorted(y_groups[y_key], key=lambda c: c['x0'])
                
                if not chars_in_line:
                    continue
                
                first_char_x = chars_in_line[0]['x0']
                line_text = ''.join([char['text'] for char in chars_in_line])
                
                if line_text.strip():
                    lines_with_position.append((first_char_x, line_text))
    
    return lines_with_position


def calculate_indent_level(x_pos, x_positions):
    """æ ¹æ® x åæ ‡è®¡ç®—ç¼©è¿›çº§åˆ«"""
    if not x_positions:
        return 0
    
    unique_x = sorted(set(x_positions))
    
    if x_pos in unique_x:
        return unique_x.index(x_pos)
    
    closest_x = min(unique_x, key=lambda x: abs(x - x_pos))
    
    if abs(x_pos - closest_x) > 10:
        insert_pos = 0
        for i, x in enumerate(unique_x):
            if x_pos > x:
                insert_pos = i + 1
            else:
                break
        return insert_pos
    
    return unique_x.index(closest_x)


def parse_hierarchy(lines_with_position):
    """è§£æå±‚çº§å…³ç³»ï¼Œæ„å»ºæ ‘å½¢ç»“æ„"""
    if not lines_with_position:
        return []
    
    x_positions = [x for x, _ in lines_with_position if x > 0]
    nodes = []
    root_nodes = []
    root_index = 0
    
    for x_pos, line_text in lines_with_position:
        indent_level = calculate_indent_level(x_pos, x_positions)
        content = line_text.strip()
        
        if not content:
            continue
        
        content = re.sub(r'^[â€¢\-\*]\s*', '', content)
        content = content.strip()
        
        if not content:
            continue
        
        while nodes and nodes[-1]["level"] >= indent_level:
            nodes.pop()
        
        if not nodes:
            node_id = f"root_{root_index}"
            root_index += 1
        else:
            parent = nodes[-1]["node"]
            parent_id = parent.get("id", "")
            child_index = len(parent.get("children", []))
            
            if parent_id.startswith("root_"):
                node_id = f"{parent_id}_child_{child_index}"
            else:
                node_id = f"{parent_id}_child_{child_index}"
        
        node = {
            "id": node_id,
            "title": content,
            "children": []
        }
        
        if not nodes:
            root_nodes.append(node)
            nodes.append({"level": indent_level, "node": node})
        else:
            parent = nodes[-1]["node"]
            parent["children"].append(node)
            nodes.append({"level": indent_level, "node": node})
    
    return root_nodes


def upgrade_to_mindmap_format(data, level=0, parent_side=None, parent_id=None, index=0, siblings_count=1, used_ids=None):
    """å°† title æ ¼å¼å‡çº§ä¸º label æ ¼å¼ï¼ˆæ·»åŠ  id, label, sideï¼‰"""
    if used_ids is None:
        used_ids = set()
    
    # å¦‚æœå·²ç»æ˜¯æ–°æ ¼å¼ï¼ˆæœ‰ labelï¼‰ï¼Œç›´æ¥è¿”å›
    if isinstance(data, dict) and 'label' in data:
        return data
    
    # æ—§æ ¼å¼ï¼ˆæœ‰ titleï¼‰ï¼Œéœ€è¦è½¬æ¢
    if isinstance(data, dict) and 'title' in data:
        title = data.get('title', '')
        
        # ç”Ÿæˆ ID
        node_id = data.get('id')
        if not node_id:
            base_id = slugify(title)
            if not base_id:
                base_id = f'node-{level}-{index}'
            
            candidate_ids = []
            if parent_id:
                candidate_ids.append(f"{parent_id}-{base_id}")
            candidate_ids.append(base_id)
            
            node_id = None
            for candidate in candidate_ids:
                if candidate not in used_ids:
                    node_id = candidate
                    break
            
            if not node_id:
                original_id = candidate_ids[0]
                suffix = 1
                while node_id is None or node_id in used_ids:
                    node_id = f"{original_id}-{suffix}"
                    suffix += 1
            
            used_ids.add(node_id)
        
        # åˆ†é… side
        side = data.get('side')
        if not side:
            if level == 0:
                side = 'center'
            elif parent_side == 'center':
                # ä¸€çº§èŠ‚ç‚¹ï¼šå¹³åˆ†å·¦å³
                side = 'left' if index < siblings_count / 2 else 'right'
            else:
                # ç»§æ‰¿çˆ¶èŠ‚ç‚¹æ–¹å‘
                side = parent_side
        
        # å¤„ç†å­èŠ‚ç‚¹
        children = []
        child_siblings_count = len(data.get('children', []))
        for child_index, child in enumerate(data.get('children', [])):
            upgraded_child = upgrade_to_mindmap_format(
                child, 
                level + 1, 
                side, 
                node_id, 
                child_index, 
                child_siblings_count,
                used_ids
            )
            children.append(upgraded_child)
        
        return {
            "id": node_id,
            "label": title,
            "side": side,
            "children": children
        }
    
    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œé€’å½’å¤„ç†
    if isinstance(data, list):
        return [upgrade_to_mindmap_format(item, level, parent_side, parent_id, idx, len(data), used_ids) 
                for idx, item in enumerate(data)]
    
    return data


def process_pdf_file(pdf_path, output_path):
    """å¤„ç†å•ä¸ª PDF æ–‡ä»¶"""
    try:
        print(f"  ğŸ“„ æå– PDF æ–‡æœ¬...")
        lines_with_position = extract_text_from_pdf(pdf_path)
        print(f"  âœ… æå–äº† {len(lines_with_position)} è¡Œæ–‡æœ¬")
        
        print(f"  ğŸ”„ è§£æå±‚çº§å…³ç³»...")
        root_nodes = parse_hierarchy(lines_with_position)
        print(f"  âœ… è§£æå®Œæˆï¼Œæ‰¾åˆ° {len(root_nodes)} ä¸ªæ ¹èŠ‚ç‚¹")
        
        print(f"  ğŸ”„ å‡çº§ä¸ºæ€ç»´å¯¼å›¾æ ¼å¼...")
        upgraded_data = upgrade_to_mindmap_format(root_nodes)
        print(f"  âœ… æ ¼å¼å‡çº§å®Œæˆ")
        
        # å†™å…¥è¾“å‡ºæ–‡ä»¶
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(upgraded_data, f, ensure_ascii=False, indent=2)
        
        return True, None
    except Exception as e:
        import traceback
        return False, f"{str(e)}\n{traceback.format_exc()}"


def main():
    # é…ç½®è·¯å¾„
    mindmap_raw_dir = Path('mindmap_raw')
    public_mindmaps_dir = Path('public/mindmaps')
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    public_mindmaps_dir.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰ PDF æ–‡ä»¶
    pdf_files = list(mindmap_raw_dir.glob('*.pdf'))
    
    if not pdf_files:
        print("âŒ åœ¨ mindmap_raw/ ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° PDF æ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(pdf_files)} ä¸ª PDF æ–‡ä»¶")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {public_mindmaps_dir}")
    print("-" * 60)
    
    success_count = 0
    error_count = 0
    skipped_count = 0
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for pdf_file in sorted(pdf_files):
        filename = pdf_file.name
        
        # æŸ¥æ‰¾å¯¹åº”çš„ç« èŠ‚ç¼–å·ï¼ˆå¤„ç†æ–‡ä»¶åä¸­çš„ç©ºæ ¼ï¼‰
        chapter = None
        filename_normalized = filename.strip()  # å»é™¤å‰åç©ºæ ¼
        for pdf_name, chapter_num in PDF_TO_CHAPTER.items():
            pdf_name_normalized = pdf_name.strip()
            if filename_normalized.lower() == pdf_name_normalized.lower():
                chapter = chapter_num
                break
        
        if not chapter:
            print(f"â­ï¸  è·³è¿‡: {filename} (æœªæ‰¾åˆ°å¯¹åº”çš„ç« èŠ‚æ˜ å°„)")
            skipped_count += 1
            continue
        
        # è·å–è¾“å‡ºæ–‡ä»¶å
        output_filename = CHAPTER_TO_FILENAME.get(chapter)
        if not output_filename:
            print(f"â­ï¸  è·³è¿‡: {filename} (æœªæ‰¾åˆ°å¯¹åº”çš„è¾“å‡ºæ–‡ä»¶å)")
            skipped_count += 1
            continue
        
        output_path = public_mindmaps_dir / output_filename
        
        print(f"ğŸ”„ å¤„ç†: {filename} -> {output_filename}")
        print(f"   ç« èŠ‚: {chapter}")
        
        success, error = process_pdf_file(pdf_file, output_path)
        
        if success:
            print(f"âœ… æˆåŠŸ: {output_path}")
            success_count += 1
        else:
            print(f"âŒ å¤±è´¥: {filename}")
            print(f"   é”™è¯¯: {error}")
            error_count += 1
        print()
    
    print("-" * 60)
    print(f"ğŸ“Š å¤„ç†å®Œæˆ:")
    print(f"   âœ… æˆåŠŸ: {success_count} ä¸ªæ–‡ä»¶")
    print(f"   âŒ å¤±è´¥: {error_count} ä¸ªæ–‡ä»¶")
    print(f"   â­ï¸  è·³è¿‡: {skipped_count} ä¸ªæ–‡ä»¶")
    print(f"   ğŸ“‚ è¾“å‡ºç›®å½•: {public_mindmaps_dir.absolute()}")

if __name__ == "__main__":
    main()
